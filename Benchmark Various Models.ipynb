{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3105a4f2",
   "metadata": {},
   "source": [
    "# Benchmark Various Models for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fe22a",
   "metadata": {},
   "source": [
    "This notebook loads the benchmark Logistic regression, Random Forest and XGBoost models for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6c06a3",
   "metadata": {},
   "source": [
    "### Define the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c10001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e22265",
   "metadata": {},
   "source": [
    "### Load database required for removing stopword and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16360f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Siva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Siva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Siva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Downloads all english dictionary words\n",
    "nltk.download('words')\n",
    "english_words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b309a2",
   "metadata": {},
   "source": [
    "### Define a function to normalize words in a sentence\n",
    "We do the following\n",
    "+ Convert all words to lower case, so we are doing not analyzing words with different case as different words\n",
    "+ Drop any stop words like I, me, this, is ...\n",
    "+ Remove words that are not in english dictionary. \n",
    "+ Remove punctuations\n",
    "+ Lemmatize words. This is converting different forms of a word to a base form.  E.g convert word like caring to care, bats to bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bafb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = \"!@#$%^&*()_-+={[}]|\\:;'<,>.?/~`\"\n",
    "\n",
    "def to_words(text):\n",
    "    words = []\n",
    "    tokens = re.findall('\\w+', text)\n",
    "    for w in tokens:\n",
    "        # Convert to lower\n",
    "        w = w.lower()\n",
    "        \n",
    "        # Remove punctuations\n",
    "        w = \"\".join([char for char in w if char not in punctuations])\n",
    "        \n",
    "        # Don't add word if it is a stopword\n",
    "        if w not in stop_words:      \n",
    "            \n",
    "            # Make sure it is valid english word\n",
    "            if w in english_words:\n",
    "                # Lemmatize word\n",
    "                w = lemmatizer.lemmatize(w, 'v')  #Assume most of the review is verb part of the speech (POS)\n",
    "                words.append(w)\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47172a3",
   "metadata": {},
   "source": [
    "### Define a function that will load the reviews file and convert it to normalized words and return the sentiment labels and words as array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ba4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(txt_bz_file):\n",
    "    sentiments = []\n",
    "    reviews = []\n",
    "    \n",
    "    with bz2.open(txt_bz_file, \"rt\", encoding='utf-8') as bz_file:\n",
    "        for line in bz_file:\n",
    "            # Label and review are separated by space\n",
    "            label, review = line.split(' ', maxsplit=1)\n",
    "            \n",
    "            # label has a format __label__2  we just need the last number\n",
    "            sentiments.append(int(label[9:]))\n",
    "            \n",
    "            # The title and the body are separated by :, so we split them \n",
    "            title, body = review.split(':', maxsplit=1)\n",
    "            \n",
    "            title_part = \" \".join(to_words(title))\n",
    "            body_part = \" \".join(to_words(body))\n",
    "            \n",
    "            sentence = \" \".join([title_part, body_part])\n",
    "            reviews.append(sentence)\n",
    "    return sentiments, reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa87c9",
   "metadata": {},
   "source": [
    "### Load the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e72fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiments, train_reviews = load_data('data/sample_train.ft.txt.bz2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed54c2",
   "metadata": {},
   "source": [
    "### Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ca60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiments, test_reviews = load_data('data/sample_test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e1f26",
   "metadata": {},
   "source": [
    "### Do count vectorization and create a dataframe for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d7d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# max_df=0.85 - Ignore words that occur in 85% of the reviews. They are not going to help and are usually words like \"the\"\n",
    "# min_df=5 - Ignore words that happen less than 5 times in the entire dataset. Since they are very rare, they won't be of any use\n",
    "count_vect = CountVectorizer(max_df=0.85, min_df=5)  \n",
    "\n",
    "# We need the vectorizer to account for all words that may only exists in test data, so lets fit the vectorizer with all words f\n",
    "count_vect.fit(train_reviews + test_reviews)\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "\n",
    "train_counts = count_vect.transform(train_reviews)\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_counts)\n",
    "train_df = pd.DataFrame(train_tfidf.toarray(), \n",
    "             columns=count_vect.get_feature_names())\n",
    "\n",
    "test_counts = count_vect.transform(test_reviews)\n",
    "test_tfidf = tfidf_transformer.fit_transform(test_counts)\n",
    "test_df = pd.DataFrame(test_tfidf.toarray(), \n",
    "             columns=count_vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68f14d",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cf22f",
   "metadata": {},
   "source": [
    "Build a LogisticRegression model and see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1159809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of LogisticRegression =  0.846\n",
      "Confusion Matrix for LogisticRegression\n",
      "[[420  78]\n",
      " [ 76 426]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(train_df, train_sentiments)\n",
    "\n",
    "# Predict\n",
    "test_sentiments_predicted = clf.predict(test_df)\n",
    "\n",
    "# Print accuracy score and confusion matrix\n",
    "\n",
    "print('Accuracy score of LogisticRegression = ', accuracy_score(test_sentiments, test_sentiments_predicted))\n",
    "\n",
    "print('Confusion Matrix for LogisticRegression')\n",
    "print(confusion_matrix(test_sentiments, test_sentiments_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88880e18",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f3362",
   "metadata": {},
   "source": [
    "Build a RandomForest model and see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f6f8149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy Score for RandomForest =  0.841\n",
      "Confusion Matrix for RandomForest\n",
      "[[405  93]\n",
      " [ 66 436]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#hyper_params = { \n",
    "#    'n_estimators': [16, 32, 64, 128, 256, 500],\n",
    "#    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#    'max_depth' : [10, 15, 20, 30, 40],\n",
    "#    'criterion' :['gini', 'entropy']\n",
    "#}\n",
    "\n",
    "#rfc = GridSearchCV(RandomForestClassifier(), hyper_params, cv= 5)\n",
    "#print(\"Best Parameters: {}\".format(rfc.best_params_))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=128, max_features='sqrt', max_depth=30, criterion='gini')\n",
    "rfc.fit(train_df, train_sentiments)\n",
    "test_sentiments_predicted = rfc.predict(test_df)\n",
    "\n",
    "print(\"Acuracy Score for RandomForest = \", accuracy_score(test_sentiments, test_sentiments_predicted))\n",
    "print('Confusion Matrix for RandomForest')\n",
    "print(confusion_matrix(test_sentiments, test_sentiments_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238ec6b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f8174f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Acuracy Score for XGBoost =  0.841\n",
      "Confusion Matrix for XGBoost\n",
      "[[405  93]\n",
      " [ 66 436]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_df, train_sentiments)\n",
    "test_sentiments_predicted = rfc.predict(test_df)\n",
    "\n",
    "print(\"Acuracy Score for XGBoost = \", accuracy_score(test_sentiments, test_sentiments_predicted))\n",
    "print('Confusion Matrix for XGBoost')\n",
    "print(confusion_matrix(test_sentiments, test_sentiments_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a16c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
